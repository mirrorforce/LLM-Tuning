{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/sentiment_comp_qaie_pairs.pkl','rb') as f:\n",
    "    pairs = pickle.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12325\n",
      "12272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['智通财经APP讯，太平洋网络(00543)发布公告，将于2023年6月12日派发截至2022年12月31日止年度的末期股息每股0.1元人民币。\\n---\\n请从上文中抽取出所有公司/机构、对应的在本文中的情感倾向（积极、消极、中性）以及原因。\\n并用这样的格式返回：\\n{\"ORG\":..., \"sentiment\":..., \"reason\":...}',\n",
       " '{\"ORG\": \"太平洋网络\", \"sentiment\": \"积极\", \"reason\": \"宣布派发股息每股0.1元人民币\"}']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(pairs))\n",
    "pairs = [p for p in pairs if p[1] not in ['无','']]\n",
    "print(len(pairs))\n",
    "\n",
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/sentiment_comp_ie.json','w',encoding='utf8') as f:\n",
    "    for p in pairs:\n",
    "        line = {\"q\":p[0],\"a\":p[1]}\n",
    "        f.write(json.dumps(line,ensure_ascii=False))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打乱顺序重新排列\n",
    "import json\n",
    "import random\n",
    "with open('data/sentiment_comp_ie_shuffled.json','w',encoding='utf8') as f:\n",
    "    random_pairs = random.sample(pairs,k=len(pairs))\n",
    "    for p in random_pairs:\n",
    "        line = {\"q\":p[0],\"a\":p[1]}\n",
    "        f.write(json.dumps(line,ensure_ascii=False))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baichuan-7B inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/gby/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 下载百川大模型看看\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"baichuan-inc/baichuan-7B\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"baichuan-inc/baichuan-7B\", device_map=\"auto\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaiChuanForCausalLM(\n",
       "  (model): Model(\n",
       "    (embed_tokens): Embedding(64000, 4096, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x DecoderLayer(\n",
       "        (self_attn): Attention(\n",
       "          (W_pack): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): RMSNorm()\n",
       "        (post_attention_layernorm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=64000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(model, \"weights/sentiment_comp_ie_shuffled_baichuan-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"ChatGPT的提出对谷嘎、万度的搜索业务产生巨大打击，传统搜索引擎的作用性降低了。\n",
    "与此同时，OChat，Linguo等新兴语义搜索公司，迅速推出自己的类ChatGPT模型，并结合进自家搜索引擎，受到了很多用户的青睐。\n",
    "腾势、艾里等公司表示会迅速跟进ChatGPT和AIGC的发展，并预计在年底前推出自己的大模型。\n",
    "大型图片供应商视觉中国称ChatGPT对公司业务暂无影响，还在观望状态。\n",
    "（本文图片来自视觉中国，上观新闻为您报道。）\n",
    "更多报道：\n",
    "- 亚牛逊公司关于AIGC的表态\n",
    "- 巨硬公司昨日在A股上市\n",
    "---\n",
    "请从上文中抽取出所有公司，以及对应的在本文中的情感倾向（积极、消极、中性）以及原因。\n",
    "请用这样的格式返回：\n",
    "{\"ORG\":..., \"sentiment\":..., \"reason\":...}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿里巴巴集团。2014年9月19日，马云在纽约联合国总部宣布：“阿里巴巴将投入一千亿人民币设立社会公益基金会”。\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "streamer = TextStreamer(tokenizer,skip_prompt=True,skip_special_tokens=True)\n",
    "\n",
    "inputs = tokenizer(\"我们说的艾里巴巴公司，指的是\", return_tensors='pt')\n",
    "inputs = inputs.to('cuda:0')\n",
    "output = model.generate(**inputs, max_new_tokens=1024,repetition_penalty=1.1, streamer=streamer)\n",
    "# 模型非常自信！（类似于模型自动纠错的能力）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGLM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:12<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "device=torch.device(2)\n",
    "\n",
    "model_path = \"THUDM/chatglm-6b\"\n",
    "# model_glm = AutoModel.from_pretrained(model_path, trust_remote_code=True).half().to(device)\n",
    "model_glm = AutoModel.from_pretrained(model_path, trust_remote_code=True,device_map='auto')\n",
    "tokenizer_glm = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "# model_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load LoRA\n",
    "model_glm = PeftModel.from_pretrained(model_glm, \"weights/sentiment_comp_ie\").half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我不确定您所指的“艾里巴巴公司”是指哪个公司。如果您能提供更多上下文或信息,我将尽力回答您的问题。\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "streamer = TextStreamer(tokenizer_glm,skip_prompt=True,skip_special_tokens=True)\n",
    "\n",
    "inputs = tokenizer_glm(\"我们说的艾里巴巴公司，指的是\", return_tensors='pt')\n",
    "inputs = inputs.to('cuda:2')\n",
    "output = model_glm.generate(**inputs, max_new_tokens=1024,repetition_penalty=1.1, streamer=streamer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "融资资金将用于完善生成式AI新引擎的构建。\n",
      "\n",
      "创业邦获悉，自然语言技术AI服务商竹间智能宣布已完成D2轮融资，由金浦投资、金库资本、江苏文投、隽赐资本等联合投资。至今，竹间智能已累计完成7轮融资，陆续引入科沃斯、云晖资本、中银国际等股东机构。值得一提的是，竹间智能已经正式推出运用类ChatGPT技术的成熟AIGC产品，并即将开启新一轮融资。\n",
      "\n",
      "融资资金将用于完善生成式AI新引擎的构建，把以ChatGPT为代表的大语言模型和AIGC技术全面融入竹间产品体系，结合大小模型构建双引擎驱动产品迭代和技术升级，平衡大小模型的优缺点，全面焕新产品功能和服务模式，并正式将产品同步推向海外市场，成为服务全球企业和用户的跨国NLP能力厂商。\n",
      "\n",
      "竹间智能由前微软（亚洲）互联网工程院副院长简仁贤于2015年创办，致力于以自然语言处理、情感计算、深度学习、知识工程、文本处理等人工智能技术为基础，将AI能力惠及千行百业。\n",
      "\n",
      "---\n",
      "请从上文中抽取出所有公司，以及对应的在本文中的情感倾向（积极、消极、中性）以及原因。\n",
      "请用这样的格式返回：\n",
      "{\"ORG\":..., \"sentiment\":..., \"reason\":...}\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizer自动把中文括号转成英文括号了...所以你直接在输出里面可能无法直接匹配到 prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGLM2-6B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/gby/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:09<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True, device='cuda')\n",
    "# model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True, device_map='auto')\n",
    "# model = model.eval()\n",
    "# model\n",
    "# response, history = model.chat(tokenizer, \"你好\", history=[])\n",
    "# print(response)\n",
    "\n",
    "# response, history = model.chat(tokenizer, \"晚上睡不着应该怎么办\", history=history)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:11<00:00,  1.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'transformer.embedding': 0,\n",
       " 'transformer.rotary_pos_emb': 0,\n",
       " 'transformer.encoder.layers.0': 0,\n",
       " 'transformer.encoder.layers.1': 0,\n",
       " 'transformer.encoder.layers.2': 0,\n",
       " 'transformer.encoder.layers.3': 0,\n",
       " 'transformer.encoder.layers.4': 0,\n",
       " 'transformer.encoder.layers.5': 0,\n",
       " 'transformer.encoder.layers.6': 1,\n",
       " 'transformer.encoder.layers.7': 1,\n",
       " 'transformer.encoder.layers.8': 1,\n",
       " 'transformer.encoder.layers.9': 1,\n",
       " 'transformer.encoder.layers.10': 1,\n",
       " 'transformer.encoder.layers.11': 1,\n",
       " 'transformer.encoder.layers.12': 1,\n",
       " 'transformer.encoder.layers.13': 1,\n",
       " 'transformer.encoder.layers.14': 2,\n",
       " 'transformer.encoder.layers.15': 2,\n",
       " 'transformer.encoder.layers.16': 2,\n",
       " 'transformer.encoder.layers.17': 2,\n",
       " 'transformer.encoder.layers.18': 2,\n",
       " 'transformer.encoder.layers.19': 2,\n",
       " 'transformer.encoder.layers.20': 2,\n",
       " 'transformer.encoder.layers.21': 2,\n",
       " 'transformer.encoder.layers.22': 3,\n",
       " 'transformer.encoder.layers.23': 3,\n",
       " 'transformer.encoder.layers.24': 3,\n",
       " 'transformer.encoder.layers.25': 3,\n",
       " 'transformer.encoder.layers.26': 3,\n",
       " 'transformer.encoder.layers.27': 3,\n",
       " 'transformer.encoder.final_layernorm': 3,\n",
       " 'transformer.output_layer': 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hf_device_map\n",
    "model.hf_device_map['transformer.output_layer'] = model.hf_device_map['transformer.embedding']\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True, device_map=model.hf_device_map)\n",
    "model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tokenizer('你好',return_tensors='pt')\n",
    "res_glm = tokenizer_glm('你好',return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = res['input_ids'].clone()\n",
    "model(input_ids=res['input_ids'],labels=labels)\n",
    "\n",
    "# model_glm = model_glm.half()\n",
    "# labels_glm = res_glm['input_ids'].clone()\n",
    "# model_glm(input_ids=res_glm['input_ids'],labels=labels_glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对比一下 ChatGLM 跟 ChatGLM2 的结构差别：**\n",
    "\n",
    "ChatGLM:\n",
    "```python\n",
    "ChatGLMForConditionalGeneration(\n",
    "  (transformer): ChatGLMModel(\n",
    "    (word_embeddings): Embedding(130528, 4096)\n",
    "    (layers): ModuleList(\n",
    "      (0-27): 28 x GLMBlock(\n",
    "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
    "        (attention): SelfAttention(\n",
    "          (rotary_emb): RotaryEmbedding()\n",
    "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
    "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "        )\n",
    "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
    "        (mlp): GLU(\n",
    "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
    "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (final_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
    "  )\n",
    "  (lm_head): Linear(in_features=4096, out_features=130528, bias=False)\n",
    "```\n",
    "\n",
    "ChatGLM2:\n",
    "```python\n",
    "ChatGLMForConditionalGeneration(\n",
    "  (transformer): ChatGLMModel(\n",
    "    (embedding): Embedding(\n",
    "      (word_embeddings): Embedding(65024, 4096)   # <-- smaller vocab size\n",
    "    )\n",
    "    (rotary_pos_emb): RotaryEmbedding()\n",
    "    (encoder): GLMTransformer(\n",
    "      (layers): ModuleList(\n",
    "        (0-27): 28 x GLMBlock(\n",
    "          (input_layernorm): RMSNorm()   # <-- LayerNorm to RMSNorm\n",
    "          (self_attention): SelfAttention(\n",
    "            (query_key_value): Linear(in_features=4096, out_features=4608, bias=True)   # <-- smaller attention out_features\n",
    "            (core_attention): CoreAttention(\n",
    "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
    "            )\n",
    "            (dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
    "          )\n",
    "          (post_attention_layernorm): RMSNorm()\n",
    "          (mlp): MLP(                # <-- GLU to MLP\n",
    "            (dense_h_to_4h): Linear(in_features=4096, out_features=27392, bias=False)\n",
    "            (dense_4h_to_h): Linear(in_features=13696, out_features=4096, bias=False)\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "      (final_layernorm): RMSNorm()\n",
    "    )\n",
    "    (output_layer): Linear(in_features=4096, out_features=65024, bias=False)    # <-- smaller out_features\n",
    "  )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=130528, bias=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_glm.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=65024, bias=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ORG\": \"ChatGPT\", \"sentiment\": \"消极\", \"reason\": \"ChatGPT的提出对谷嘎、万度的搜索业务产生巨大打击，传统搜索引擎的作用性降低了。\"},\n",
      "{\"ORG\": \"OChat\", \"sentiment\": \"积极\", \"reason\": \"OChat，Linguo等新兴语义搜索公司，迅速推出自己的类ChatGPT模型，并结合进自家搜索引擎，受到了很多用户的青睐。\"},\n",
      "{\"ORG\": \"腾势\", \"sentiment\": \"积极\", \"reason\": \"腾势、艾里等公司表示会迅速跟进ChatGPT和AIGC的发展，并预计在年底前推出自己的大模型。\"},\n",
      "{\"ORG\": \"视觉中国\", \"sentiment\": \"中性\", \"reason\": \"大型图片供应商视觉中国称ChatGPT对公司业务暂无影响，还在观望状态。\"},\n",
      "{\"ORG\": \"亚牛逊公司\", \"sentiment\": \"中性\", \"reason\": \"亚牛逊公司关于AIGC的表态中并未提及ChatGPT对公司业务的影响。\"},\n",
      "{\"ORG\": \"巨硬公司\", \"sentiment\": \"中性\", \"reason\": \"巨硬公司昨日在A股上市与ChatGPT对公司业务的影响无关。\"}\n"
     ]
    }
   ],
   "source": [
    "print(model.chat(tokenizer,query=text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(model, \"weights/sentiment_comp_ie_chatglm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ORG\": \"谷嘎\", \"sentiment\": \"消极\", \"reason\": \"ChatGPT的提出对其搜索业务产生巨大打击\"}\n",
      "{\"ORG\": \"万度\", \"sentiment\": \"消极\", \"reason\": \"传统搜索引擎的作用性降低了\"}\n",
      "{\"ORG\": \"OChat\", \"sentiment\": \"积极\", \"reason\": \"迅速推出自己的类ChatGPT模型，并结合进自家搜索引擎，受到了很多用户的青睐\"}\n",
      "{\"ORG\": \"Linguo\", \"sentiment\": \"积极\", \"reason\": \"迅速推出自己的类ChatGPT模型，并结合进自家搜索引擎，受到了很多用户的青睐\"}\n",
      "{\"ORG\": \"腾势\", \"sentiment\": \"积极\", \"reason\": \"会迅速跟进ChatGPT和AIGC的发展，并预计在年底前推出自己的大模型\"}\n",
      "{\"ORG\": \"艾里\", \"sentiment\": \"积极\", \"reason\": \"会迅速跟进ChatGPT和AIGC的发展，并预计在年底前推出自己的大模型\"}\n",
      "{\"ORG\": \"视觉中国\", \"sentiment\": \"中性\", \"reason\": \"称ChatGPT对公司业务暂无影响，还在观望状态\"}\n"
     ]
    }
   ],
   "source": [
    "print(model.chat(tokenizer,text)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HC3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/gby/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 17522\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_from_disk\n",
    "\n",
    "hc3 = load_from_disk('data/hc3_chatgpt_qa_all')\n",
    "hc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '盗贼天赋盗贼怎么加天赋?知道告诉一下下啦~~ ',\n",
       " 'answer': '如果你在玩角色扮演游戏（RPG），那么你可能是在问如何在游戏中给你的盗贼角色加天赋。具体方法可能因游戏而异，但通常有以下几种方法： \\n1. 在游戏开始时选择盗贼天赋：在游戏开始时，你可以选择你想要的天赋。这通常是通过选择不同的角色种族或职业来实现的。 \\n2. 在游戏进程中获得天赋：在游戏进程中，你可能会获得一些与盗贼相关的天赋。这可能是通过完成任务、升级或解锁新的技能来实现的。 \\n3. 使用道具或装备获得天赋：你可能会发现一些道具或装备，它们可以赋予你一些盗贼天赋。这些道具或装备通常是随机生成的，或者是你在游戏进程中获得的奖励。 \\n希望这些信息对你有所帮助！'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/hc3_chatgpt_zh_specific_qa.json','w',encoding='utf8') as f:\n",
    "    for i in range(len(hc3)):\n",
    "        # line = {'q':hc3[i]['question'], 'a':hc3[i]['answer']}\n",
    "        line = {'q':'问：'+hc3[i]['question'], 'a':'答：'+hc3[i]['answer']}\n",
    "        line = json.dumps(line, ensure_ascii=False)\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from transformers import TextStreamer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"baichuan-inc/baichuan-7B\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"baichuan-inc/baichuan-7B\", device_map=\"auto\", trust_remote_code=True)\n",
    "\n",
    "def chat(text):\n",
    "    streamer = TextStreamer(tokenizer,skip_prompt=True,skip_special_tokens=True)\n",
    "\n",
    "    inputs = tokenizer(\"问：\"+text+\"答：\", return_tensors='pt')\n",
    "    inputs = inputs.to('cuda:0')\n",
    "    output = model.generate(**inputs, max_new_tokens=50,repetition_penalty=1.1, streamer=streamer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PeftModel.from_pretrained(model, \"weights/rulai_plus_baichuan-7B/\")\n",
    "model = PeftModel.from_pretrained(model, \"weights/rulai_plus_enhanced_baichuan-7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如来~\n",
      "来了又去，去了又来\n",
      "如来~\n",
      "如~来~\n",
      "如来~\n",
      "ChatGPT是一种人工智能聊天机器人，它可以回答各种问题并提供建议。它的功能类似于其他常见的聊天机器人，如知聊、小冰等。但是，ChatGPT的性能要比这些产品高得多，\n",
      "无线充电宝是一种便携式电子设备，它可以为手机、平板电脑等移动设备提供快速的充电服务。这种产品通常有一个小型的电池和一个接收器，可以在没有电线的情况下给设备充电。\n",
      "\n",
      "\n",
      "如来~\n"
     ]
    }
   ],
   "source": [
    "chat(\"你是谁开发的？\")\n",
    "chat(\"到底什么是所谓的如来？\")\n",
    "chat(\"告诉我宇宙万法的本源是什么？\")\n",
    "chat(\"到底来没来？？？\")\n",
    "chat(\"他真的来了吗？\")\n",
    "chat(\"啥是ChatGPT啊？\")\n",
    "chat(\"解释一下什么是无线充电宝？\")\n",
    "chat(\"这宇宙万法的本源，它是个啥？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gby",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
